{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load raw dataset\n",
    "src = 'data/995,000_rows.csv'\n",
    "# src = 'data/SAMPLE.csv'\n",
    "raw_data = pd.read_csv(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amount of '!' (exclamations) in fake news vs. reliable news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a lot more '!'-characters in fake labelled articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "char = '!'\n",
    "\n",
    "# copy dataframe\n",
    "exclm_data = raw_data.copy(deep=True)\n",
    "\n",
    "# get count sum of exclamation points in each article\n",
    "exclm_data['exclm_count'] = exclm_data['content'].str.count(char)\n",
    "\n",
    "# get total sum of exclamation points for each type (labels)\n",
    "fake_exclm_sum = (exclm_data[ (exclm_data['type'] == 'fake')])['exclm_count'].mean()\n",
    "reliable_exclm_sum = (exclm_data[ (exclm_data['type'] == 'reliable')])['exclm_count'].mean()\n",
    "\n",
    "# plot data\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_ylabel('mean')\n",
    "ax.set_title('\\'!\\' characters in fake vs. reliable')\n",
    "\n",
    "ax.bar(['fake', 'reliable'], [fake_exclm_sum, reliable_exclm_sum])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amount of '!' (exclamations) in each type of labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'political' has most exclamations points. Second is 'fake'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "char = '!'\n",
    "\n",
    "# copy dataframe\n",
    "exclm_data = raw_data.copy(deep=True)\n",
    "\n",
    "# get count sum of exclamation points in each article\n",
    "exclm_data['exclm_count'] = exclm_data['content'].str.count(char)\n",
    "\n",
    "# get total sum of exclamation points for each type (labels)\n",
    "types = ['reliable',\n",
    "         'political',\n",
    "         'bias',\n",
    "         'fake',\n",
    "         'conspiracy',\n",
    "         'rumor',\n",
    "         'unknown',\n",
    "         'unreliable',\n",
    "         'clickbait',\n",
    "         'junksci',\n",
    "         'satire',\n",
    "         'hate'\n",
    "         ]\n",
    "\n",
    "sums = []\n",
    "for type in types:\n",
    "    sum = (exclm_data[ (exclm_data['type'] == type)])['exclm_count'].mean()\n",
    "    sums.append(sum)\n",
    "\n",
    "# plot data\n",
    "fig, ax = plt.subplots()\n",
    "plt.xticks(rotation='vertical')\n",
    "\n",
    "ax.set_ylabel('mean')\n",
    "ax.set_title('\\'!\\' characters in all article types')\n",
    "\n",
    "ax.bar(types, sums)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amount of unique words in reliable news vs. fake news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the sum of different words for each article, and make a scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.process_methods as pm\n",
    "import pandas as pd\n",
    "import os.path\n",
    "\n",
    "# copy dataframe\n",
    "# src = 'data/995,000_rows_cleaned.csv'\n",
    "src = 'data/SAMPLE_cleaned.csv'\n",
    "word_data = pd.read_csv(src)\n",
    "word_freq = pd.DataFrame()\n",
    "\n",
    "# get unique word freq for each article and add to dataframe\n",
    "# This might take a while!\n",
    "path = 'data/word_freq.csv'\n",
    "if not os.path.isfile(path):\n",
    "    word_freq = pm.word_freq(word_data, 'content_clean', 'content_word_freq')\n",
    "\n",
    "    # concat types\n",
    "    word_freq.insert(0, \"type\", word_data['type'])\n",
    "\n",
    "    # save to file\n",
    "    word_freq.to_csv('data/word_freq.csv')\n",
    "else:\n",
    "    print('File already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "src = 'data/word_freq.csv'\n",
    "word_freq = pd.read_csv(src)\n",
    "\n",
    "# get total mean of exclamation points for each type (labels)\n",
    "types = ['reliable',\n",
    "         'political',\n",
    "         'bias',\n",
    "         'fake',\n",
    "         'conspiracy',\n",
    "         'rumor',\n",
    "         'unknown',\n",
    "         'unreliable',\n",
    "         'clickbait',\n",
    "         'junksci',\n",
    "         'satire',\n",
    "         'hate'\n",
    "         ]\n",
    "\n",
    "means = []\n",
    "for type in types:\n",
    "    mean = (word_freq[ (word_freq['type'] == type)])['content_word_freq'].mean()\n",
    "    means.append(mean)\n",
    "\n",
    "# plot data\n",
    "fig, ax = plt.subplots()\n",
    "plt.xticks(rotation='vertical')\n",
    "\n",
    "ax.set_ylabel('mean')\n",
    "ax.set_title('Unique words in articles by type')\n",
    "\n",
    "ax.bar(types, means)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do Fake news have less author names then reliable news? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the barplot, it seems that 'reliable' news have more missing authors, then 'fake' news. So actually the opposite of our hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get all rows with label 'fake'\n",
    "fake_data = raw_data[(raw_data['type'] == 'fake')]\n",
    "\n",
    "# count rows for 'fake' with no author names \n",
    "fake_auth_isNull_sum = fake_data['authors'].isnull().sum()\n",
    "\n",
    "# get all rows with label 'reliable'\n",
    "reliable_data = raw_data[(raw_data['type'] == 'reliable')]\n",
    "\n",
    "# count rows for 'reliable' with no author names\n",
    "reliable_auth_isNull_sum = reliable_data['authors'].isnull().sum()\n",
    "\n",
    "# plot comparison\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_ylabel('missing author values')\n",
    "ax.set_title('Missing author values: \\'fake\\' vs. \\'reliable\\' news')\n",
    "\n",
    "ax.bar(['fake', 'reliable'], [fake_auth_isNull_sum, reliable_auth_isNull_sum])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations between word reduction rates between reliable vs. fake?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fake-news-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
