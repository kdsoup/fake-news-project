{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# This method has to be used on the cleaned dataset, otherwise \n",
    "# we'll get errors if running tokenizing of words on the unprocessed content text.\n",
    "\n",
    "# src = 'data/995,000_rows_cleaned.csv'\n",
    "src = 'data/SAMPLE_cleaned.csv'\n",
    "dst = 'data/word_freq.csv'\n",
    "\n",
    "# load data\n",
    "clean_data = pd.read_csv(src)\n",
    "word_freq = pd.DataFrame()\n",
    "\n",
    "# add type labels to dataframe \n",
    "word_freq.insert(0, \"type\", clean_data['type'])\n",
    "\n",
    "# save to file\n",
    "word_freq.to_csv(dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import swifter\n",
    "\n",
    "# This method has to be used on the cleaned dataset to get the reduction rates in the cleanup steps\n",
    "\n",
    "src = 'data/995,000_rows_cleaned.csv'\n",
    "# src = 'data/SAMPLE_cleaned.csv'\n",
    "dst = 'data/word_freq.csv'\n",
    "\n",
    "# get word freq for stopwords and stemming\n",
    "def get_word_freq(text: str) -> int:\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return len(set(tokens))\n",
    "\n",
    "# load data\n",
    "clean_data = pd.read_csv(src)\n",
    "word_freq = pd.read_csv(dst)\n",
    "\n",
    "# get word freq\n",
    "word_freq['content_word_freq'] = word_data['content_clean'].swifter.apply(get_word_freq)\n",
    "\n",
    "# word freq after removing stopwords\n",
    "word_freq['stop_word_freq'] = clean_data['content_stopword'].swifter.apply(get_word_freq)\n",
    "\n",
    "# word freq after stemming\n",
    "word_freq['stem_word_freq'] = clean_data['content_stem'].swifter.apply(get_word_freq)\n",
    "\n",
    "# save to file\n",
    "word_freq.to_csv(dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get reduction rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduction rate on stopword removal\n",
    "col_a = word_freq['content_word_freq']\n",
    "col_b = word_freq['stop_word_freq']\n",
    "word_freq['stop_reduction_rate'] = round(((col_a - col_b)/col_a) * 100, 3)\n",
    "\n",
    "# save to file\n",
    "word_freq.to_csv(dst)\n",
    "\n",
    "# reduction rate on stem removal\n",
    "col_a = word_freq['content_word_freq']\n",
    "col_b = word_freq['stem_word_freq']\n",
    "word_freq['stem_reduction_rate'] = round(((col_a - col_b)/col_a) * 100, 3)\n",
    "\n",
    "# save to file\n",
    "word_freq.to_csv(dst)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
