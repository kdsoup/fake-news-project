{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import process_methods as pm\n",
    "import pandas as pd\n",
    "import swifter\n",
    "\n",
    "src = '../data/995,000_rows.csv'\n",
    "# src = '../data/SAMPLE.csv'\n",
    "dst = src[0:-4] + '_cleaned.csv'\n",
    "\n",
    "# deep copy\n",
    "raw_data = pd.read_csv(src)\n",
    "clean_data = raw_data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty 'content' rows\n",
    "clean_data.dropna(subset=['content'], inplace=True)\n",
    "\n",
    "# remove unused columns\n",
    "clean_data.drop(['id',\n",
    "                'domain',\n",
    "                'url',\n",
    "                'scraped_at',\n",
    "                'inserted_at',\n",
    "                'updated_at',\n",
    "                'keywords',\n",
    "                'meta_keywords',\n",
    "                'meta_description',\n",
    "                'tags',\n",
    "                'summary',\n",
    "                'Unnamed: 0',\n",
    "                'source'\n",
    "                ], axis=1, inplace=True)\n",
    "\n",
    "# remove rows without type labels\n",
    "drop_null_types = clean_data[ (clean_data['type'].isnull())].index\n",
    "clean_data.drop(drop_null_types, inplace=True)\n",
    "\n",
    "# save to file\n",
    "clean_data.to_csv(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup text on 'content' column and add into new column 'content_clean'\n",
    "clean_data['content_clean'] = clean_data['content'].swifter.apply(pm.clean_text)\n",
    "\n",
    "# save to file\n",
    "clean_data.to_csv(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply remove_stopwords to 'content_clean' column and create 'content_stopword' column\n",
    "clean_data['content_stopword'] = clean_data['content_clean'].swifter.apply(pm.remove_stopwords)\n",
    "\n",
    "# save to file\n",
    "clean_data.to_csv(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming\n",
    "clean_data['content_stem'] = clean_data['content_stopword'].swifter.apply(pm.remove_word_variations)\n",
    "\n",
    "# save to file\n",
    "clean_data.to_csv(dst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fake-news-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
