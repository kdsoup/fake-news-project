{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load raw dataset\n",
    "src = 'data/training_data_features.csv'\n",
    "training_data = pd.read_csv(src)\n",
    "\n",
    "# load grouped validation data\n",
    "src_validation = 'data/validation_data_features.csv'\n",
    "validation_data = pd.read_csv(src_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 1, 'is': 1, 'sample': 1, 'text': 1, 'for': 1, 'testing': 1, 'bag': 1, 'of': 1, 'words': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def create_bag_of_words(text):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "\n",
    "    # Fit the vectorizer to the text data and transform the text\n",
    "    bag_of_words = count_vectorizer.fit_transform([text])\n",
    "\n",
    "    # Get feature names (words) from the vectorizer\n",
    "    feature_names = count_vectorizer.get_feature_names_out()\n",
    "\n",
    "    word_counts = {}\n",
    "    for col in bag_of_words.nonzero()[1]:\n",
    "        word_counts[feature_names[col]] = bag_of_words[0, col]\n",
    "\n",
    "    return word_counts\n",
    "\n",
    "\n",
    "input_text = \"This is a sample text for testing bag of words.\"\n",
    "bag_of_words_result = create_bag_of_words(input_text)\n",
    "print(bag_of_words_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Phong Phan\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      0.74      0.75     21571\n",
      "        True       0.75      0.77      0.76     22002\n",
      "\n",
      "    accuracy                           0.76     43573\n",
      "   macro avg       0.76      0.76      0.76     43573\n",
      "weighted avg       0.76      0.76      0.76     43573\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.sparse import hstack\n",
    "import pandas as pd\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_training_matrix = tfidf_vectorizer.fit_transform(training_data['content_stem'])\n",
    "\n",
    "tfidf_validation_matrix = tfidf_vectorizer.transform(validation_data['content_stem'])\n",
    "\n",
    "X_training_numeric = training_data[['date_count', 'url_count', 'exclm_count',\n",
    "                                    'content_word_freq', 'stop_word_freq', 'stem_word_freq',\n",
    "                                    'stop_reduction_rate', 'stem_reduction_rate', 'average_sentence_length']]\n",
    "\n",
    "X_training_combined = hstack((tfidf_training_matrix, X_training_numeric))\n",
    "\n",
    "X_validation_numeric = validation_data[['date_count', 'url_count', 'exclm_count',\n",
    "                                        'content_word_freq', 'stop_word_freq', 'stem_word_freq',\n",
    "                                        'stop_reduction_rate', 'stem_reduction_rate', 'average_sentence_length']]\n",
    "\n",
    "\n",
    "X_validation_combined = hstack((tfidf_validation_matrix, X_validation_numeric))\n",
    "\n",
    "y_training_data = training_data['reliable']\n",
    "y_validation_data = validation_data['reliable']\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_training_combined, y_training_data)\n",
    "\n",
    "predictions = logistic_model.predict(X_validation_combined)\n",
    "\n",
    "print(\"Logistic Regression Performance:\")\n",
    "print(classification_report(y_validation_data, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Phong Phan\\miniconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.97      0.96     21571\n",
      "        True       0.97      0.96      0.96     22002\n",
      "\n",
      "    accuracy                           0.96     43573\n",
      "   macro avg       0.96      0.96      0.96     43573\n",
      "weighted avg       0.96      0.96      0.96     43573\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_training_matrix = tfidf_vectorizer.fit_transform(training_data['content_stem'])\n",
    "tfidf_validation_matrix = tfidf_vectorizer.transform(validation_data['content_stem'])\n",
    "\n",
    "\n",
    "X_training_numeric = training_data[['date_count', 'url_count', 'exclm_count',\n",
    "                                    'content_word_freq', 'stop_word_freq', 'stem_word_freq',\n",
    "                                    'stop_reduction_rate', 'stem_reduction_rate', 'average_sentence_length']]\n",
    "X_validation_numeric = validation_data[['date_count', 'url_count', 'exclm_count',\n",
    "                                        'content_word_freq', 'stop_word_freq', 'stem_word_freq',\n",
    "                                        'stop_reduction_rate', 'stem_reduction_rate', 'average_sentence_length']]\n",
    "\n",
    "X_training_combined = hstack((tfidf_training_matrix, X_training_numeric.values))\n",
    "X_validation_combined = hstack((tfidf_validation_matrix, X_validation_numeric.values))\n",
    "\n",
    "\n",
    "y_training_data = training_data['reliable']\n",
    "y_validation_data = validation_data['reliable']\n",
    "\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=100, random_state=42)\n",
    "mlp_model.fit(X_training_combined, y_training_data)\n",
    "\n",
    "predictions = mlp_model.predict(X_validation_combined)\n",
    "\n",
    "print(classification_report(y_validation_data, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With single hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack\n",
    "import pandas as pd\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_training_matrix = tfidf_vectorizer.fit_transform(training_data['content_stem'])\n",
    "\n",
    "tfidf_validation_matrix = tfidf_vectorizer.transform(validation_data['content_stem'])\n",
    "\n",
    "numeric_features = ['date_count', 'url_count', 'exclm_count',\n",
    "                    'content_word_freq', 'stop_word_freq', 'stem_word_freq',\n",
    "                    'stop_reduction_rate', 'stem_reduction_rate', 'average_sentence_length']\n",
    "\n",
    "X_training_numeric = training_data[numeric_features]\n",
    "X_validation_numeric = validation_data[numeric_features]\n",
    "\n",
    "X_training_combined = hstack((tfidf_training_matrix, X_training_numeric))\n",
    "X_validation_combined = hstack((tfidf_validation_matrix, X_validation_numeric))\n",
    "\n",
    "# Scale input features\n",
    "scaler = StandardScaler(with_mean=False)  # Pass with_mean=False for sparse matrices\n",
    "X_training_scaled = scaler.fit_transform(X_training_combined)\n",
    "X_validation_scaled = scaler.transform(X_validation_combined)\n",
    "\n",
    "y_training_data = training_data['reliable']\n",
    "y_validation_data = validation_data['reliable']\n",
    "\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, batch_size=256, early_stopping=True, verbose=True)\n",
    "mlp_model.fit(X_training_scaled, y_training_data)\n",
    "\n",
    "predictions = mlp_model.predict(X_validation_scaled)\n",
    "\n",
    "print(\"MLP Classifier Performance:\")\n",
    "print(classification_report(y_validation_data, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.sparse import hstack\n",
    "import pandas as pd\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_training_matrix = tfidf_vectorizer.fit_transform(training_data['content_stem'])\n",
    "\n",
    "tfidf_validation_matrix = tfidf_vectorizer.transform(validation_data['content_stem'])\n",
    "\n",
    "X_training_numeric = training_data[['num_count', 'date_count', 'url_count', 'comma_count', 'exclm_count',\n",
    "                                    'content_word_freq', 'stop_word_freq', 'stem_word_freq',\n",
    "                                    'stop_reduction_rate', 'stem_reduction_rate', 'average_sentence_length']]\n",
    "\n",
    "X_training_combined = hstack((tfidf_training_matrix, X_training_numeric))\n",
    "\n",
    "X_validation_numeric = validation_data[['num_count', 'date_count', 'url_count', 'comma_count', 'exclm_count',\n",
    "                                        'content_word_freq', 'stop_word_freq', 'stem_word_freq',\n",
    "                                        'stop_reduction_rate', 'stem_reduction_rate', 'average_sentence_length']]\n",
    "\n",
    "X_validation_combined = hstack((tfidf_validation_matrix, X_validation_numeric))\n",
    "\n",
    "y_training_data = training_data['reliable']\n",
    "y_validation_data = validation_data['reliable']\n",
    "\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_training_combined, y_training_data)\n",
    "\n",
    "predictions = svm_model.predict(X_validation_combined)\n",
    "\n",
    "print(\"Support Vector Machine (SVM) Performance:\")\n",
    "print(classification_report(y_validation_data, predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
