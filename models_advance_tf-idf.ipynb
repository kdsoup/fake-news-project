{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load data\n",
    "src = 'data/training_data_features.csv'\n",
    "training_data_raw = pd.read_csv(src, index_col=0)\n",
    "\n",
    "src = 'data/validation_data_features.csv'\n",
    "validation_data_raw = pd.read_csv(src, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, HashingVectorizer\n",
    "\n",
    "X_train = training_data_raw['content_stem']\n",
    "X_val = validation_data_raw['content_stem']\n",
    "\n",
    "# bag of words\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "# Learn a vocabulary dictionary of all word tokens in the entire training set.\n",
    "vectorizer.fit(X_train)\n",
    "# Transform documents to document-term matrix.\n",
    "X_train_cnts = vectorizer.transform(X_train)\n",
    "X_val_cnts = vectorizer.transform(X_val)\n",
    "\n",
    "# tf-idf\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "# Learn the idf vector (global term weights) from the document-term matrix\n",
    "tfidf_transformer.fit(X_train_cnts)\n",
    "# Transform a count matrix to a tf or tf-idf representation\n",
    "X_train_tfidf = tfidf_transformer.transform(X_train_cnts)\n",
    "X_val_tfidf = tfidf_transformer.transform(X_val_cnts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine TF-IDF matrix with simple features\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "features = [\n",
    "    'date_count', \n",
    "    'url_count', \n",
    "    'exclm_count',\n",
    "    'content_word_freq', \n",
    "    'stop_word_freq', \n",
    "    'stem_word_freq',\n",
    "    'stop_reduction_rate', \n",
    "    'stem_reduction_rate', \n",
    "    'average_sentence_length'\n",
    "]\n",
    "\n",
    "# combine features and TF-IDF\n",
    "X_training_numeric = training_data_raw[features]\n",
    "X_training_combined = hstack((X_train_tfidf, X_training_numeric))\n",
    "\n",
    "X_validation_numeric = validation_data_raw[features]\n",
    "X_validation_combined = hstack((X_val_tfidf, X_validation_numeric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression w. Baseline + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGISTIC REGRESSION\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "x_train = X_training_combined\n",
    "y_train = training_data_raw['reliable']\n",
    "\n",
    "x_val = X_validation_combined\n",
    "y_val = validation_data_raw['reliable']\n",
    "\n",
    "# create logistic reg. model, and train it\n",
    "log_reg_model = LogisticRegression(max_iter=200)\n",
    "log_reg_model.fit(x_train, y_train)\n",
    "\n",
    "# test the model and report performance\n",
    "predictions = log_reg_model.predict(x_val)\n",
    "print('LOGISTIC REGRESSION w/ BASELINE, TF-IDF')\n",
    "print(classification_report(y_val, predictions))\n",
    "\n",
    "# Confusion matrix of classification errors\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# ConfusionMatrixDisplay.from_estimator(log_reg_model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression w. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGISTIC REGRESSION\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# x_train = X_training_combined\n",
    "x_train = X_train_tfidf\n",
    "y_train = training_data_raw['reliable']\n",
    "\n",
    "# x_val = X_validation_combined\n",
    "x_val = X_val_tfidf\n",
    "y_val = validation_data_raw['reliable']\n",
    "\n",
    "# create logistic reg. model, and train it\n",
    "log_reg_model = LogisticRegression(max_iter=200)\n",
    "log_reg_model.fit(x_train, y_train)\n",
    "\n",
    "# test the model and report performance\n",
    "predictions = log_reg_model.predict(x_val)\n",
    "print('LOGISTIC REGRESSION w/ TF-IDF')\n",
    "print(classification_report(y_val, predictions))\n",
    "\n",
    "# Confusion matrix of classification errors\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# ConfusionMatrixDisplay.from_estimator(log_reg_model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes w. Baseline and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAIVE BAYES\n",
    "# REF: https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "x_train = X_training_combined\n",
    "y_train = training_data_raw['reliable']\n",
    "\n",
    "x_val = X_validation_combined\n",
    "y_val = validation_data_raw['reliable']\n",
    "\n",
    "# naive bayes model\n",
    "nb_model = MultinomialNB().fit(x_train, y_train)\n",
    "\n",
    "# predictions\n",
    "y_pred = nb_model.predict(x_val)\n",
    "print('NAIVE BAYES w/ BASELINE, TF-IDF')\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Confusion matrix of classification errors\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# ConfusionMatrixDisplay.from_estimator(nb_model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes w. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAIVE BAYES\n",
    "# REF: https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# x_train = X_training_combined\n",
    "x_train = X_train_tfidf\n",
    "y_train = training_data_raw['reliable']\n",
    "\n",
    "# x_val = X_validation_combined\n",
    "x_val = X_val_tfidf\n",
    "y_val = validation_data_raw['reliable']\n",
    "\n",
    "# naive bayes model\n",
    "nb_model = MultinomialNB().fit(x_train, y_train)\n",
    "\n",
    "# predictions\n",
    "y_pred = nb_model.predict(x_val)\n",
    "print('NAIVE BAYES w/ TF-IDF')\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Confusion matrix of classification errors\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# ConfusionMatrixDisplay.from_estimator(nb_model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network with Simple Features + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEURAL NETWORK\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale input features\n",
    "scaler = StandardScaler(with_mean=False)  # Pass with_mean=False for sparse matrices\n",
    "X_training_scaled = scaler.fit_transform(X_training_combined)\n",
    "X_validation_scaled = scaler.transform(X_validation_combined)\n",
    "\n",
    "y_training_data = training_data_raw['reliable']\n",
    "y_validation_data = validation_data_raw['reliable']\n",
    "\n",
    "# MLP model with 1 hidden layer and 10 neurones, with the default rectified linear unit function.\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(10), max_iter=500, batch_size=256, early_stopping=True, verbose=True)\n",
    "mlp_model.fit(X_training_scaled, y_training_data)\n",
    "\n",
    "predictions = mlp_model.predict(X_validation_scaled)\n",
    "\n",
    "print(\"MLP CLASSIFIER w/ FEATURES + TF-IDF\")\n",
    "print(classification_report(y_validation_data, predictions))\n",
    "\n",
    "# Confusion matrix of classification errors\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_estimator(mlp_model, X_validation_scaled, y_validation_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fake-news-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
